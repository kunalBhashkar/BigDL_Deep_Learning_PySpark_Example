{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/depthcol.jpeg)\n",
    "<pre>         (Image credit: Stanford cs231n <a>http://cs231n.github.io/assets/cnn/depthcol.jpeg)</a></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node in convolutional layer is associated with a 3D block (height x width x channel) in the input tensor. Moreover, the convolutional layer itself has multiple output channels. So the layer is parameterized by a 4 dimensional weight tensor, commonly called a convolutional kernel. The output tensor is produced by sliding the kernel across the input image skipping locations according to a pre-defined stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/envs/deep_learning/lib/python3.6/site-packages/bigdl/util/engine.py:41: UserWarning: Find both SPARK_HOME and pyspark. You may need to check whether they match with each other. SPARK_HOME environment variable is set to: /home/kunal/Downloads/spark-2.4.7-bin-hadoop2.7/, and pyspark is found in: /home/kunal/anaconda3/envs/deep_learning/lib/python3.6/site-packages/pyspark/__init__.py. If they are unmatched, please use one source only to avoid conflict. For example, you can unset SPARK_HOME and use pyspark only.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepending /home/kunal/anaconda3/envs/deep_learning/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n"
     ]
    }
   ],
   "source": [
    "#BigDL to express a CNN\n",
    "#import packages\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from bigdl.nn.keras.topology import Sequential\n",
    "from bigdl.nn.keras.layer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In BigDL, we use Convolutiona2D() to apply a 2D convolution over an input image composed of several input planes. This function takes a few important parameters: number of convolutional filters(```nbFilter```), number of rows in the convolutional kernal(```nbRow```), number of columns in the convolutional kernal(```nbCol```), string representation of the activation function(```activation```) and the shape of the input layer(```input_shape```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/envs/deep_learning/lib/python3.6/site-packages/bigdl/nn/keras/topology.py:213: UserWarning: bigdl.nn.keras is deprecated in 0.11. Recommend to use Analytics Zoo's Keras API.\n",
      "  warnings.warn(\"bigdl.nn.keras is deprecated in 0.11. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createKerasSequential\n",
      "creating: createKerasConvolution2D\n"
     ]
    }
   ],
   "source": [
    "#Define Layers\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(20, 3, 3, activation=\"relu\", input_shape=(1, 28, 28)))\n",
    "input = np.random.random([2, 1, 28, 28])\n",
    "output = model.forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** \n",
    "\n",
    "The number of examples (64) remains unchanged. The number of channels (also called filters) has increased to 20. And because the (3,3) kernel can only be applied in 26 different heights and widths (without the kernel busting over the image border), our output is 26,26. There are some weird padding tricks we can use when we want the input and output to have the same height and width dimensions, but we wonâ€™t get into that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createKerasSequential\n",
      "creating: createKerasMaxPooling2D\n"
     ]
    }
   ],
   "source": [
    "#Average pooling, default value for downscaling the weights vertically and horizontally is (2, 2)\n",
    "model = Sequential()\n",
    "model.add(MaxPooling2D(input_shape = (1, 28, 28)))\n",
    "input = np.random.random([2, 1, 28, 28])\n",
    "output = model.forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createKerasSequential\n",
      "creating: createKerasFlatten\n",
      "[[[[0.18321077 0.6766386  0.71398925]\n",
      "   [0.09295621 0.82980218 0.76773918]]\n",
      "\n",
      "  [[0.5726227  0.8689477  0.49284268]\n",
      "   [0.53057877 0.52126079 0.14199241]]]\n",
      "\n",
      "\n",
      " [[[0.54276957 0.53055823 0.51371165]\n",
      "   [0.77832433 0.87990441 0.49560211]]\n",
      "\n",
      "  [[0.94963403 0.47248744 0.65917649]\n",
      "   [0.49838467 0.60026824 0.06189344]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.18321078, 0.6766386 , 0.71398926, 0.09295621, 0.82980216,\n",
       "        0.7677392 , 0.5726227 , 0.8689477 , 0.49284267, 0.5305788 ,\n",
       "        0.5212608 , 0.1419924 ],\n",
       "       [0.54276955, 0.5305582 , 0.51371163, 0.7783243 , 0.8799044 ,\n",
       "        0.4956021 , 0.949634  , 0.47248745, 0.65917647, 0.49838468,\n",
       "        0.60026824, 0.06189344]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It flattens the input without affecting the batch size\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(2, 2, 3)))\n",
    "input = np.random.random([2, 2, 2, 3])\n",
    "output = model.forward(input)\n",
    "print(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#Getting MINIST Data\n",
    "from bigdl.dataset import mnist\n",
    "from bigdl.util.common import *\n",
    "\n",
    "mnist_path = \"./data/mnist\"\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data(mnist_path)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createKerasSequential\n",
      "creating: createKerasReshape\n",
      "creating: createKerasConvolution2D\n",
      "creating: createKerasMaxPooling2D\n",
      "creating: createKerasConvolution2D\n",
      "creating: createKerasMaxPooling2D\n",
      "creating: createKerasFlatten\n",
      "creating: createKerasDense\n",
      "creating: createKerasDense\n",
      "(None, 28, 28, 1)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "#Convolutional neural network model\n",
    "num_fc = 512\n",
    "num_outputs = 10\n",
    "model = Sequential()\n",
    "model.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\n",
    "model.add(Convolution2D(20, 3, 3, activation=\"relu\", input_shape=(1, 28, 28)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(50, 3, 3, activation=\"relu\", name=\"conv2_5x5\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_fc, activation=\"relu\", name=\"fc1\"))\n",
    "model.add(Dense(num_outputs, activation=\"softmax\", name=\"fc2\"))\n",
    "#Print Model input and output shape\n",
    "print(model.get_input_shape())\n",
    "print(model.get_output_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createClassNLLCriterion\n",
      "creating: createTop1Accuracy\n"
     ]
    }
   ],
   "source": [
    "#Training configure\n",
    "from bigdl.nn.criterion import *\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute training\n",
    "model.fit(X_train, Y_train, batch_size=8, nb_epoch=1,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
